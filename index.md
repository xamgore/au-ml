### Билет 1.

1. <mark>[Препроцессинг. Масштабирование. Нормировка. Полиномиальные признаки. One-hot encoding.](https://xamgore.github.io/au-ml/conspect.html#%D0%BF%D1%80%D0%B5%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%B8%D0%BD%D0%B3-%D0%BC%D0%B0%D1%81%D1%88%D1%82%D0%B0%D0%B1%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5-%D0%BD%D0%BE%D1%80%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0-%D0%BF%D0%BE%D0%BB%D0%B8%D0%BD%D0%BE%D0%BC%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5-%D0%BF%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA%D0%B8-one-hot-encoding)</mark>

2. [Кластеризация. kMeans, MeanShift, DBSCAN, Affinity Propagation.](#%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F-kmeans-meanshift-dbscan-affinity-propagation)

### Билет 2.

1. Смещение и дисперсия (bias and variance). Понятие средней гипотезы.
2. Ансамблевые методы. Soft and Hard Voting. Bagging. Случайные леса. AdaBoost.

### Билет 3.
1. Типы обучения: с учителем, без учителя, с подкреплением, с частичным участием учителя, активное обучение.
2. Boosted Decision Trees.

### Билет 4.
1. [Ошибка внутри и вне выборки. Ошибка обобщения. Неравенство Хёфдинга. Валидация и кросс-валидация.](conspect.html#ошибка-внутри-и-вне-выборки-ошибка-обобщения-неравенство-хёфдинга-валидация-и-кросс-валидация)
2. Линейная регрессия. Полиномиальная регрессия. Гребневая регрессия.

### Билет 5.
1. Размерность Вапника-Червоненкиса. Размерность Вапника-Червоненкиса для перцептрона.
2. Логистическая регрессия. Градиентный спуск.

### Билет 6.
1. [Пороговые условия. Эффективность по Парето. Presicion-Recall и ROC кривые. AUC.](conspect.html#пороговые-условия-эффективность-по-парето-presicion-recall-и-roc-кривые-auc)
2. Ансамблевые методы регрессии. RANSAC. Theil-Sen. Huber.

### Билет 7.
1. [Перцептрон. Перцептрон с карманом.](conspect.html#перцептрон-перцептрон-с-карманом)
2. Метод опорных векторов. Постановка задачи. Формулировка и решение двойственной задачи. Типы опорных векторов. Ядра.

### Билет 8.
1. Гипотезы и дихотомии. Функция роста. Точка поломки. Доказательство полиномиальности функции роста в присутствии точки поломки.
2. [Деревья решений. Информационный выигрыш, критерий Джини. Регуляризация деревьев. Небрежные решающие деревья.](conspect.html#деревья-решений-информационный-выигрыш-критерий-Джини-регуляризация-деревьев-небрежные-решающие-деревья)

### Билет 9.
1. Байесовский классификатор. Типы оценки распределений признаков (Gaussian, Bernoulli, Multinomial). EM алгоритм.
2. Нейронные сети. Перцептрон Розенблатта. Функции активации. Обратное распространение градиента. Softmax.

### Билет 10.
1. Стохастическая оптимизация. Hill Climb. Отжиг. Генетический алгоритм.
2. [Метрические классификаторы. kNN. WkNN. Отбор эталонов. DROP5. Kdtree.](conspect.html#%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5-%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80%D1%8B-knn-wknn-%D0%BE%D1%82%D0%B1%D0%BE%D1%80-%D1%8D%D1%82%D0%B0%D0%BB%D0%BE%D0%BD%D0%BE%D0%B2-drop5-kdtree)

<style>a{color:inherit!important;text-decoration:underline orange !important;}</style>
